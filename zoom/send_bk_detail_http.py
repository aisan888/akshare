import uvicorn
import logging
import socket
from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import JSONResponse
import tushare as ts
from datetime import datetime


# ===================== 1. æ—¥å¿—é…ç½®ï¼ˆå…³é”®ï¼šæ’æŸ¥è¯·æ±‚æ˜¯å¦åˆ°è¾¾ï¼‰ =====================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(funcName)s - %(message)s",
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ===================== 2. é…ç½®é¡¹ =====================
HTTP_HOST = "localhost"
HTTP_PORT = 8000
DEFAULT_TRADE_DATE = "20251213"


TUSHARE_TOKEN = "168b63e0215b64bf1f7cc2558f3547bdd7b9d9168896e7ce6a14c79e7559"
TUSHARE_HTTP_URL = "http://42.194.163.97:5000"
DEFAULT_FIELDS = "ts_code,name,turnover_rate,up_num,down_num"

# ===================== 3. åˆå§‹åŒ–å‰ç½®æ£€æŸ¥ =====================
def check_port_available(port: int) -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind((HTTP_HOST, port))
            return True
        except OSError:
            logger.error(f"ç«¯å£ {port} å·²è¢«å ç”¨ï¼è¯·æ›´æ¢ç«¯å£æˆ–å…³é—­å ç”¨è¿›ç¨‹")
            return False


def init_tushare() -> ts.pro_api:

    try:
        pro = ts.pro_api(TUSHARE_TOKEN)
        # è¦†ç›–è‡ªå®šä¹‰æ¥å£åœ°å€ï¼ˆé’ˆå¯¹ç§æœ‰éƒ¨ç½²çš„Tushareï¼‰
        pro._DataApi__token = TUSHARE_TOKEN
        pro._DataApi__http_url = TUSHARE_HTTP_URL

        # é¢„æ ¡éªŒTushareè¿æ¥ï¼ˆè°ƒç”¨åŸºç¡€æ¥å£æµ‹è¯•ï¼‰
        pro.trade_cal(exchange='', start_date='20251201', end_date='20251201')
        logger.info("âœ… Tushareæ¥å£åˆå§‹åŒ–æˆåŠŸ")
        return pro
    except Exception as e:
        logger.error(f"âŒ Tushareåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        raise RuntimeError(f"Tushareåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")


# æ£€æŸ¥ç«¯å£å¯ç”¨æ€§
if not check_port_available(HTTP_PORT):
    exit(1)

# åˆå§‹åŒ–Tushare
pro = init_tushare()

# ===================== 4. åˆå§‹åŒ–FastAPIï¼ˆæ·»åŠ ä¸­é—´ä»¶è®°å½•æ‰€æœ‰è¯·æ±‚ï¼‰ =====================
app = FastAPI(
    title="æ¿å—è¯¦æƒ…æŸ¥è¯¢API",
    description="C++å®¢æˆ·ç«¯HTTPæ¥å£ï¼šæŸ¥è¯¢DCæ¿å—æˆåˆ†è‚¡è¯¦æƒ…",
    version="1.0.0"
)


# å…¨å±€ä¸­é—´ä»¶ï¼šè®°å½•æ‰€æœ‰å…¥ç«™è¯·æ±‚ï¼ˆå…³é”®ï¼šç¡®è®¤è¯·æ±‚æ˜¯å¦åˆ°è¾¾æœåŠ¡ç«¯ï¼‰
@app.middleware("http")
async def log_requests(request, call_next):
    logger.info(f"ğŸ“¥ æ”¶åˆ°è¯·æ±‚ | æ–¹æ³•ï¼š{request.method} | è·¯å¾„ï¼š{request.url.path} | å‚æ•°ï¼š{request.query_params}")
    response = await call_next(request)
    logger.info(f"ğŸ“¤ å“åº”è¿”å› | çŠ¶æ€ç ï¼š{response.status_code}")
    return response


# ===================== 5. æ ¸å¿ƒæ¥å£ï¼ˆå¢å¼ºæ ¡éªŒ+è¯¦ç»†æ—¥å¿—ï¼‰ =====================
@app.get("/api/dc_member", response_class=JSONResponse)
async def get_dc_member(
        ts_code: str = Query(..., description="æ¿å—ä»£ç ï¼Œç¤ºä¾‹ï¼šBK1184.DC"),
        trade_date: str = Query(DEFAULT_TRADE_DATE, description="äº¤æ˜“æ—¥ï¼Œæ ¼å¼ï¼šYYYYMMDD")
):

    if not ts_code:
        raise HTTPException(status_code=400, detail="æ¿å—ä»£ç ä¸èƒ½ä¸ºç©º")
    if len(trade_date) != 8 or not trade_date.isdigit():
        raise HTTPException(status_code=400, detail="äº¤æ˜“æ—¥æ ¼å¼é”™è¯¯ï¼Œéœ€ä¸º8ä½æ•°å­—ï¼ˆYYYYMMDDï¼‰")
    if not (ts_code.startswith("BK") and "." in ts_code and ts_code.split(".")[-1] == "DC"):
        raise HTTPException(status_code=400, detail=f"æ¿å—ä»£ç æ ¼å¼é”™è¯¯ï¼ç¤ºä¾‹ï¼šBK1184.DCï¼Œå½“å‰ï¼š{ts_code}")

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢æ¿å—æ•°æ® | ts_code={ts_code} | trade_date={trade_date}")

        # è°ƒç”¨Tushareæ¥å£
        df = pro.dc_member(trade_date=trade_date, ts_code=ts_code)
        logger.info(f"Tushareè¿”å›æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        # æ•°æ®æ¸…æ´—
        df = df.reset_index(drop=True).dropna().drop_duplicates()

        # æ„é€ å“åº”
        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {"ts_code": ts_code, "trade_date": trade_date},
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"æ¿å—æ•°æ®æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


@app.get("/api/dc_index", response_class=JSONResponse)
async def get_dc_index(
        trade_date: str = Query(DEFAULT_TRADE_DATE, description="äº¤æ˜“æ—¥ï¼Œæ ¼å¼ï¼šYYYYMMDD"),
        fields: str = Query(DEFAULT_FIELDS, description="æŸ¥è¯¢å­—æ®µï¼Œå¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ï¼Œç¤ºä¾‹ï¼šts_code,name,turnover_rate")
):
    """
    HTTP GETæ¥å£ï¼šæŸ¥è¯¢DCæ¿å—æŒ‡æ•°ä¿¡æ¯
    :param trade_date: äº¤æ˜“æ—¥ï¼ˆå¯é€‰ï¼Œé»˜è®¤20251213ï¼‰
    :param fields: æŸ¥è¯¢å­—æ®µï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šts_code,name,turnover_rate,up_num,down_numï¼‰
    :return: JSONæ ¼å¼çš„æ¿å—æŒ‡æ•°ä¿¡æ¯
    """
    # å‚æ•°æ ¡éªŒ
    # 1. äº¤æ˜“æ—¥æ ¡éªŒ
    if len(trade_date) != 8 or not trade_date.isdigit():
        raise HTTPException(status_code=400, detail="äº¤æ˜“æ—¥æ ¼å¼é”™è¯¯ï¼Œéœ€ä¸º8ä½æ•°å­—ï¼ˆYYYYMMDDï¼‰")

    # 2. å­—æ®µå‚æ•°æ ¡éªŒï¼ˆéç©º + æ ¼å¼åˆæ³•ï¼‰
    if not fields:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µä¸èƒ½ä¸ºç©º")
    # è¿‡æ»¤ç©ºå­—æ®µï¼Œå»é‡
    field_list = [f.strip() for f in fields.split(",") if f.strip()]
    if not field_list:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µæ ¼å¼é”™è¯¯ï¼Œå¤šä¸ªå­—æ®µè¯·ç”¨é€—å·åˆ†éš”ï¼ˆç¤ºä¾‹ï¼šts_code,nameï¼‰")
    # é‡æ–°æ‹¼æ¥å»é‡åçš„å­—æ®µï¼ˆé¿å…é‡å¤å­—æ®µï¼‰
    clean_fields = ",".join(list(set(field_list)))

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢æ¿å—æŒ‡æ•°æ•°æ® | trade_date={trade_date} | fields={clean_fields}")

        # è°ƒç”¨Tushare dc_indexæ¥å£
        df = pro.dc_index(trade_date=trade_date, fields=clean_fields)
        logger.info(f"Tushareè¿”å›æŒ‡æ•°æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        # æ•°æ®æ¸…æ´—ï¼ˆå’ŒåŸæœ‰æ¥å£ä¿æŒä¸€è‡´çš„æ¸…æ´—é€»è¾‘ï¼‰
        df = df.reset_index(drop=True).dropna().drop_duplicates()

        # æ„é€ å“åº”ï¼ˆå’ŒåŸæœ‰æ¥å£æ ¼å¼ä¿æŒä¸€è‡´ï¼Œä¿è¯å‰ç«¯å…¼å®¹ï¼‰
        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {
                "trade_date": trade_date,
                "fields": clean_fields,  # è¿”å›æ¸…æ´—åçš„å­—æ®µ
                "original_fields": fields  # ä¿ç•™åŸå§‹è¯·æ±‚å­—æ®µï¼ˆä¾¿äºæ’æŸ¥ï¼‰
            },
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"æ¿å—æŒ‡æ•°æ•°æ®æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushare dc_indexæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼ˆdc_indexï¼‰ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


# æ–°å¢ï¼šstock_basicå¯é€‰å‚æ•°æšä¸¾ï¼ˆç”¨äºå‚æ•°æ ¡éªŒï¼‰
VALID_EXCHANGES = ["", "XSHE", "SZSE", "XSHG", "SHSE", "BJSE"]  # ç©º=å…¨éƒ¨ï¼Œæ·±å¸‚/æ²ªå¸‚/åŒ—äº¤æ‰€
VALID_LIST_STATUSES = ["L", "D", "P"]  # L=ä¸Šå¸‚ï¼ŒD=é€€å¸‚ï¼ŒP=æš‚åœä¸Šå¸‚
DEFAULT_STOCK_FIELDS = "ts_code,symbol,name,area,industry,list_date"
# http://127.0.0.1:8000/api/stock_basic?fields=ts_code,symbol,market,exchange,list_status,is_hs,name,area,industry,list_date
# ===================== 7. æ–°å¢æ ¸å¿ƒæ¥å£ï¼šstock_basic =====================
@app.get("/api/stock_basic", response_class=JSONResponse)
async def get_stock_basic(
        exchange: str = Query("", description=f"äº¤æ˜“æ‰€ä»£ç ï¼Œå¯é€‰å€¼ï¼š{VALID_EXCHANGES}ï¼ˆç©º=å…¨éƒ¨ï¼‰"),
        list_status: str = Query("L", description=f"ä¸Šå¸‚çŠ¶æ€ï¼Œå¯é€‰å€¼ï¼š{VALID_LIST_STATUSES}ï¼ˆL=ä¸Šå¸‚ï¼ŒD=é€€å¸‚ï¼ŒP=æš‚åœä¸Šå¸‚ï¼‰"),
        fields: str = Query(DEFAULT_STOCK_FIELDS,
                            description="æŸ¥è¯¢å­—æ®µï¼Œå¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ï¼Œç¤ºä¾‹ï¼šts_code,symbol,name,area")
):

    if exchange not in VALID_EXCHANGES:
        raise HTTPException(
            status_code=400,
            detail=f"äº¤æ˜“æ‰€ä»£ç é”™è¯¯ï¼å¯é€‰å€¼ï¼š{VALID_EXCHANGES}ï¼Œå½“å‰ï¼š{exchange}"
        )

    # 2. ä¸Šå¸‚çŠ¶æ€æ ¡éªŒ
    if list_status not in VALID_LIST_STATUSES:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸Šå¸‚çŠ¶æ€é”™è¯¯ï¼å¯é€‰å€¼ï¼š{VALID_LIST_STATUSES}ï¼ˆL=ä¸Šå¸‚ï¼ŒD=é€€å¸‚ï¼ŒP=æš‚åœä¸Šå¸‚ï¼‰ï¼Œå½“å‰ï¼š{list_status}"
        )

    # 3. å­—æ®µå‚æ•°æ ¡éªŒï¼ˆå»ç©ºã€å»é‡ï¼‰
    if not fields:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µä¸èƒ½ä¸ºç©º")
    field_list = [f.strip() for f in fields.split(",") if f.strip()]
    if not field_list:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µæ ¼å¼é”™è¯¯ï¼Œå¤šä¸ªå­—æ®µè¯·ç”¨é€—å·åˆ†éš”ï¼ˆç¤ºä¾‹ï¼šts_code,nameï¼‰")
    clean_fields = ",".join(list(set(field_list)))

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ | exchange={exchange} | list_status={list_status} | fields={clean_fields}")

        # è°ƒç”¨Tushare stock_basicæ¥å£
        df = pro.stock_basic(
            exchange='',
            list_status='',
            fields=clean_fields
        )
        logger.info(f"Tushareè¿”å›è‚¡ç¥¨åŸºæœ¬æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        # æ•°æ®æ¸…æ´—ï¼ˆå’ŒåŸæœ‰æ¥å£ä¿æŒä¸€è‡´çš„é€»è¾‘ï¼‰
        df = df.reset_index(drop=True).dropna().drop_duplicates()

        # æ„é€ å“åº”ï¼ˆæ ¼å¼å’ŒåŸæœ‰æ¥å£å®Œå…¨ä¸€è‡´ï¼Œä¿è¯å‰ç«¯å…¼å®¹ï¼‰
        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {
                "exchange": exchange,
                "list_status": list_status,
                "fields": clean_fields,
                "original_fields": fields
            },
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushare stock_basicæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼ˆstock_basicï¼‰ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")

import re
TS_CODE_PATTERN = re.compile(r"^\d{6}\.(SH|SZ|BJ)$")
# ===================== 4. æ ¸å¿ƒæ¥å£ï¼šrt_kï¼ˆæ— ä»»ä½•æ•°é‡é™åˆ¶ï¼‰ =====================
@app.get("/api/rt_k", response_class=JSONResponse)
async def get_rt_k(
        ts_codes: str = Query(..., description="ä»£ç åˆ—è¡¨ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”ï¼ˆæ ¼å¼ï¼š600000.SHï¼Œæ— æ•°é‡é™åˆ¶ï¼‰")
):

    raw_codes = [code.strip() for code in ts_codes.split(",") if code.strip()]
    if not raw_codes:
        raise HTTPException(status_code=400, detail="ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")


    valid_codes = []
    invalid_codes = []
    for code in raw_codes:
        if TS_CODE_PATTERN.match(code):
            valid_codes.append(code)
        else:
            invalid_codes.append(code)

    # 3. ä»£ç å»é‡ï¼ˆé¿å…é‡å¤æŸ¥è¯¢ï¼Œä¸é™åˆ¶æ•°é‡ï¼‰
    valid_codes = list(set(valid_codes))
    logger.info(
        f"è§£æè‚¡ç¥¨ä»£ç  | åŸå§‹æ•°é‡ï¼š{len(raw_codes)} | æœ‰æ•ˆæ•°é‡ï¼š{len(valid_codes)} | æ— æ•ˆæ•°é‡ï¼š{len(invalid_codes)}"
    )

    # 4. æ£€æŸ¥æœ‰æ•ˆä»£ç æ˜¯å¦ä¸ºç©º
    if not valid_codes:
        raise HTTPException(status_code=400, detail=f"æ— æœ‰æ•ˆè‚¡ç¥¨ä»£ç ï¼æ— æ•ˆä»£ç ï¼š{invalid_codes}")

    # 5. å•æ¬¡è°ƒç”¨Tushare rt_kæ¥å£ï¼ˆä¼ å…¥æ‰€æœ‰æœ‰æ•ˆä»£ç ï¼Œæ— æ•°é‡é™åˆ¶ï¼‰
    try:
        logger.info(f"è°ƒç”¨Tushare rt_kæ¥å£ | æœ‰æ•ˆä»£ç æ•°ï¼š{len(valid_codes)}ï¼ˆæ— æ•°é‡é™åˆ¶ï¼‰")
        valid_codes_str = ",".join(valid_codes)

        # æ ¸å¿ƒè°ƒç”¨ï¼šä¸€æ¬¡æ€§ä¼ å…¥æ‰€æœ‰æœ‰æ•ˆä»£ç ï¼ˆæ— è®ºæ•°é‡å¤šå°‘ï¼‰
        df = pro.rt_k(ts_code=valid_codes_str)

        # 6. æ•°æ®æ¸…æ´—
        all_data = []
        if not df.empty:
            # é‡ç½®ç´¢å¼• + å»ç©ºå€¼ + æŒ‰è‚¡ç¥¨ä»£ç å»é‡
            df = df.reset_index(drop=True).dropna().drop_duplicates(subset=["ts_code"])
            all_data = df.to_dict(orient="records")
            logger.info(f"æ¥å£è°ƒç”¨æˆåŠŸ | è¿”å›æ•°æ®è¡Œæ•°ï¼š{len(all_data)}")
        else:
            logger.warning("Tushareæ¥å£è¿”å›ç©ºæ•°æ®")

        # 7. æç®€å“åº”ï¼ˆæ— ä»»ä½•å¤šä½™é™åˆ¶å­—æ®µï¼‰
        response_data = {
            "code": 0,          # 0=æˆåŠŸï¼Œ1=å¤±è´¥
            "msg": "success",   # å“åº”ä¿¡æ¯
            "data": all_data,   # æ ¸å¿ƒKçº¿æ•°æ®
            "meta": {           # å…ƒä¿¡æ¯ï¼ˆä»…å±•ç¤ºç»Ÿè®¡ï¼Œæ— é™åˆ¶ï¼‰
                "total_input_codes": len(raw_codes),
                "valid_code_count": len(valid_codes),
                "invalid_codes": invalid_codes,
                "return_data_count": len(all_data),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        }

        return response_data

    # å¼‚å¸¸å¤„ç†ï¼ˆä»…æ•è·æ¥å£è°ƒç”¨é”™è¯¯ï¼‰
    except ts.exceptions.TushareError as e:
        logger.error(f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")

# ===================== 6. å¿ƒè·³æ£€æµ‹æ¥å£ï¼ˆç®€åŒ–+æ—¥å¿—ï¼‰ =====================
@app.get("/api/heartbeat", response_class=JSONResponse)
async def heartbeat():
    logger.info("å¤„ç†å¿ƒè·³æ£€æµ‹è¯·æ±‚")
    return {
        "code": 0,
        "msg": "pong",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "service_status": "running",
        "tushare_status": "connected"  # æ–°å¢Tushareè¿æ¥çŠ¶æ€
    }


# ===================== 7. æ ¹è·¯å¾„æ¥å£ï¼ˆæµ‹è¯•æœåŠ¡æ˜¯å¦å­˜æ´»ï¼‰ =====================
@app.get("/", response_class=JSONResponse)
async def root():
    return {
        "code": 0,
        "msg": "æœåŠ¡è¿è¡Œä¸­",
        "docs_url": f"http://{HTTP_HOST}:{HTTP_PORT}/docs",  # Swaggeræ–‡æ¡£åœ°å€
        "redoc_url": f"http://{HTTP_HOST}:{HTTP_PORT}/redoc"
    }


# ===================== 8. å¯åŠ¨æœåŠ¡ï¼ˆå¢å¼ºé…ç½®ï¼‰ =====================
if __name__ == "__main__":
    logger.info(f"ğŸš€ å¯åŠ¨FastAPIæœåŠ¡ | åœ°å€ï¼šhttp://{HTTP_HOST}:{HTTP_PORT}")
    logger.info(f"ğŸ“š APIæ–‡æ¡£åœ°å€ï¼šhttp://{HTTP_HOST}:{HTTP_PORT}/docs")

    # å¯åŠ¨UVicornï¼ˆæ·»åŠ workers+è¶…æ—¶é…ç½®ï¼Œé€‚é…ç”Ÿäº§ç¯å¢ƒï¼‰
    uvicorn.run(
        app=app,
        host=HTTP_HOST,
        port=HTTP_PORT,
        log_level="info",
        workers=1,  # å•è¿›ç¨‹ï¼ˆè°ƒè¯•æ›´ç®€å•ï¼‰ï¼Œç”Ÿäº§ç¯å¢ƒå¯æ”¹ä¸º2-4
        timeout_keep_alive=60  # é•¿è¿æ¥è¶…æ—¶
    )