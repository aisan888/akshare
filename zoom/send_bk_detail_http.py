import json
import socket
import logging
import uvicorn
import tushare as ts
from datetime import datetime
from fastapi.responses import JSONResponse
from fastapi import FastAPI, Query, HTTPException

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(funcName)s - %(message)s",
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

HTTP_HOST = "localhost"
HTTP_PORT = 8000

TUSHARE_TOKEN = "168b63e0215b64bf1f7cc2558f3547bdd7b9d9168896e7ce6a14c79e7559"
TUSHARE_HTTP_URL = "http://42.194.163.97:5000"


def check_port_available(port: int) -> bool:
    """æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind((HTTP_HOST, port))
            return True
        except OSError:
            logger.error(f"ç«¯å£ {port} å·²è¢«å ç”¨ï¼è¯·æ›´æ¢ç«¯å£æˆ–å…³é—­å ç”¨è¿›ç¨‹")
            return False


def init_tushare() -> ts.pro_api:
    try:
        pro = ts.pro_api(TUSHARE_TOKEN)

        pro._DataApi__token = TUSHARE_TOKEN
        pro._DataApi__http_url = TUSHARE_HTTP_URL

        pro.trade_cal(exchange='', start_date='20251201', end_date='20251201')
        logger.info("âœ… Tushareæ¥å£åˆå§‹åŒ–æˆåŠŸ")
        return pro
    except Exception as e:
        logger.error(f"âŒ Tushareåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")
        raise RuntimeError(f"Tushareåˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}")


if not check_port_available(HTTP_PORT):
    exit(1)

pro = init_tushare()

app = FastAPI(
    title="æ¿å—è¯¦æƒ…æŸ¥è¯¢API",
    description="C++å®¢æˆ·ç«¯HTTPæ¥å£ï¼šæŸ¥è¯¢DCæ¿å—æˆåˆ†è‚¡è¯¦æƒ…",
    version="1.0.0"
)


def saveJson(save_path, response_data):
    try:
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(response_data, f, ensure_ascii=False, indent=4, sort_keys=False)
        logger.info(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°ï¼š{save_path}")
    except Exception as e:
        logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ï¼š{str(e)}")


@app.middleware("http")
async def log_requests(request, call_next):
    logger.info(f"ğŸ“¥ æ”¶åˆ°è¯·æ±‚ | æ–¹æ³•ï¼š{request.method} | è·¯å¾„ï¼š{request.url.path} | å‚æ•°ï¼š{request.query_params}")
    response = await call_next(request)
    logger.info(f"ğŸ“¤ å“åº”è¿”å› | çŠ¶æ€ç ï¼š{response.status_code}")
    return response


DEFAULT_TRADE_DATE = "20251213"


@app.get("/api/dc_member", response_class=JSONResponse)
async def get_dc_member(
        ts_code: str = Query(..., description="æ¿å—ä»£ç ï¼Œç¤ºä¾‹ï¼šBK1184.DC"),
        trade_date: str = Query(DEFAULT_TRADE_DATE, description="äº¤æ˜“æ—¥ï¼Œæ ¼å¼ï¼šYYYYMMDD")
):
    if not ts_code:
        raise HTTPException(status_code=400, detail="æ¿å—ä»£ç ä¸èƒ½ä¸ºç©º")
    if len(trade_date) != 8 or not trade_date.isdigit():
        raise HTTPException(status_code=400, detail="äº¤æ˜“æ—¥æ ¼å¼é”™è¯¯ï¼Œéœ€ä¸º8ä½æ•°å­—ï¼ˆYYYYMMDDï¼‰")
    if not (ts_code.startswith("BK") and "." in ts_code and ts_code.split(".")[-1] == "DC"):
        raise HTTPException(status_code=400, detail=f"æ¿å—ä»£ç æ ¼å¼é”™è¯¯ï¼ç¤ºä¾‹ï¼šBK1184.DCï¼Œå½“å‰ï¼š{ts_code}")

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢æ¿å—æ•°æ® | ts_code={ts_code} | trade_date={trade_date}")

        df = pro.dc_member(trade_date=trade_date, ts_code=ts_code)
        logger.info(f"Tushareè¿”å›æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        df = df.reset_index(drop=True).dropna().drop_duplicates()

        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {"ts_code": ts_code, "trade_date": trade_date},
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"æ¿å—æ•°æ®æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


DEFAULT_FIELDS = "ts_code,name,turnover_rate,up_num,down_num"


@app.get("/api/dc_index", response_class=JSONResponse)
async def get_dc_index(
        trade_date: str = Query(DEFAULT_TRADE_DATE, description="äº¤æ˜“æ—¥ï¼Œæ ¼å¼ï¼šYYYYMMDD"),
        fields: str = Query(DEFAULT_FIELDS, description="æŸ¥è¯¢å­—æ®µï¼Œå¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ï¼Œç¤ºä¾‹ï¼šts_code,name,turnover_rate")
):
    if len(trade_date) != 8 or not trade_date.isdigit():
        raise HTTPException(status_code=400, detail="äº¤æ˜“æ—¥æ ¼å¼é”™è¯¯ï¼Œéœ€ä¸º8ä½æ•°å­—ï¼ˆYYYYMMDDï¼‰")

    if not fields:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µä¸èƒ½ä¸ºç©º")

    field_list = [f.strip() for f in fields.split(",") if f.strip()]
    if not field_list:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µæ ¼å¼é”™è¯¯ï¼Œå¤šä¸ªå­—æ®µè¯·ç”¨é€—å·åˆ†éš”ï¼ˆç¤ºä¾‹ï¼šts_code,nameï¼‰")

    clean_fields = ",".join(list(set(field_list)))

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢æ¿å—æŒ‡æ•°æ•°æ® | trade_date={trade_date} | fields={clean_fields}")

        df = pro.dc_index(trade_date=trade_date, fields=clean_fields)
        logger.info(f"Tushareè¿”å›æŒ‡æ•°æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        df = df.reset_index(drop=True).dropna().drop_duplicates()

        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {
                "trade_date": trade_date,
                "fields": clean_fields,
                "original_fields": fields
            },
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"æ¿å—æŒ‡æ•°æ•°æ®æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushare dc_indexæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼ˆdc_indexï¼‰ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


VALID_EXCHANGES = ["", "XSHE", "SZSE", "XSHG", "SHSE", "BJSE"]
VALID_LIST_STATUSES = ["L", "D", "P"]
DEFAULT_STOCK_FIELDS = "ts_code,symbol,name,area,industry,list_date"


@app.get("/api/stock_basic", response_class=JSONResponse)
async def get_stock_basic(
        exchange: str = Query("", description=f"äº¤æ˜“æ‰€ä»£ç ï¼Œå¯é€‰å€¼ï¼š{VALID_EXCHANGES}ï¼ˆç©º=å…¨éƒ¨ï¼‰"),
        list_status: str = Query("L", description=f"ä¸Šå¸‚çŠ¶æ€ï¼Œå¯é€‰å€¼ï¼š{VALID_LIST_STATUSES}ï¼ˆL=ä¸Šå¸‚ï¼ŒD=é€€å¸‚ï¼ŒP=æš‚åœä¸Šå¸‚ï¼‰"),
        fields: str = Query(DEFAULT_STOCK_FIELDS,
                            description="æŸ¥è¯¢å­—æ®µï¼Œå¤šä¸ªå­—æ®µç”¨é€—å·åˆ†éš”ï¼Œç¤ºä¾‹ï¼šts_code,symbol,name,area")
):
    if exchange not in VALID_EXCHANGES:
        raise HTTPException(
            status_code=400,
            detail=f"äº¤æ˜“æ‰€ä»£ç é”™è¯¯ï¼å¯é€‰å€¼ï¼š{VALID_EXCHANGES}ï¼Œå½“å‰ï¼š{exchange}"
        )

    if list_status not in VALID_LIST_STATUSES:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸Šå¸‚çŠ¶æ€é”™è¯¯ï¼å¯é€‰å€¼ï¼š{VALID_LIST_STATUSES}ï¼ˆL=ä¸Šå¸‚ï¼ŒD=é€€å¸‚ï¼ŒP=æš‚åœä¸Šå¸‚ï¼‰ï¼Œå½“å‰ï¼š{list_status}"
        )

    if not fields:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µä¸èƒ½ä¸ºç©º")
    field_list = [f.strip() for f in fields.split(",") if f.strip()]
    if not field_list:
        raise HTTPException(status_code=400, detail="æŸ¥è¯¢å­—æ®µæ ¼å¼é”™è¯¯ï¼Œå¤šä¸ªå­—æ®µè¯·ç”¨é€—å·åˆ†éš”ï¼ˆç¤ºä¾‹ï¼šts_code,nameï¼‰")
    clean_fields = ",".join(list(set(field_list)))

    try:
        logger.info(f"å¼€å§‹æŸ¥è¯¢åŸºæœ¬ä¿¡æ¯ | exchange={exchange} | list_status={list_status} | fields={clean_fields}")

        df = pro.stock_basic(
            exchange='',
            list_status='',
            fields=clean_fields
        )
        logger.info(f"Tushareè¿”å›åŸºæœ¬æ•°æ®è¡Œæ•°ï¼š{len(df) if not df.empty else 0}")

        df = df.reset_index(drop=True).dropna().drop_duplicates()

        response_data = {
            "code": 0,
            "msg": "success",
            "data": df.to_dict(orient="records"),
            "request_params": {
                "exchange": exchange,
                "list_status": list_status,
                "fields": clean_fields,
                "original_fields": fields
            },
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        logger.info(f"åŸºæœ¬ä¿¡æ¯æŸ¥è¯¢æˆåŠŸ | è¿”å›æ•°æ®æ¡æ•°ï¼š{len(response_data['data'])}")
        return response_data

    except ts.exceptions.TushareError as e:
        logger.error(f"Tushare stock_basicæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯æœªçŸ¥é”™è¯¯ï¼ˆstock_basicï¼‰ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


import re

TS_CODE_PATTERN = re.compile(r"^\d{6}\.(SH|SZ|BJ)$")


@app.get("/api/rt_k", response_class=JSONResponse)
async def get_rt_k(ts_codes: str = Query(..., description="æ ¼å¼ï¼š600000.SH,600001.SH")):
    raw_codes = [code.strip() for code in ts_codes.split(",") if code.strip()]
    if not raw_codes:
        raise HTTPException(status_code=400, detail="ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

    valid_codes = []
    invalid_codes = []
    for code in raw_codes:
        if TS_CODE_PATTERN.match(code):
            valid_codes.append(code)
        else:
            invalid_codes.append(code)

    valid_codes = list(set(valid_codes))
    logger.info(
        f"è§£æä»£ç  | åŸå§‹æ•°é‡ï¼š{len(raw_codes)} | æœ‰æ•ˆæ•°é‡ï¼š{len(valid_codes)} | æ— æ•ˆæ•°é‡ï¼š{len(invalid_codes)}"
    )

    if not valid_codes:
        raise HTTPException(status_code=400, detail=f"æ— æœ‰æ•ˆä»£ç ï¼æ— æ•ˆä»£ç ï¼š{invalid_codes}")

    try:
        logger.info(f"è°ƒç”¨Tushare rt_kæ¥å£ | æœ‰æ•ˆä»£ç æ•°ï¼š{len(valid_codes)}ï¼ˆæ— æ•°é‡é™åˆ¶ï¼‰")
        valid_codes_str = ",".join(valid_codes)

        df = pro.rt_k(ts_code=valid_codes_str)

        all_data = []
        if not df.empty:
            df = df.reset_index(drop=True).dropna().drop_duplicates(subset=["ts_code"])
            all_data = df.to_dict(orient="records")
            logger.info(f"æ¥å£è°ƒç”¨æˆåŠŸ | è¿”å›æ•°æ®è¡Œæ•°ï¼š{len(all_data)}")
        else:
            logger.warning("Tushareæ¥å£è¿”å›ç©ºæ•°æ®")

        response_data = {
            "code": 0,
            "msg": "success",
            "data": all_data,
            "meta": {
                "total_input_codes": len(raw_codes),
                "valid_code_count": len(valid_codes),
                "invalid_codes": invalid_codes,
                "return_data_count": len(all_data),
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
        }

        return response_data


    except ts.exceptions.TushareError as e:
        logger.error(f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Tushareæ¥å£è°ƒç”¨å¤±è´¥ï¼š{str(e)}")
    except Exception as e:
        logger.error(f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æœåŠ¡ç«¯é”™è¯¯ï¼š{str(e)}")


@app.get("/api/heartbeat", response_class=JSONResponse)
async def heartbeat():
    logger.info("å¤„ç†å¿ƒè·³æ£€æµ‹è¯·æ±‚")
    return {
        "code": 0,
        "msg": "pong",
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "service_status": "running",
        "tushare_status": "connected"
    }


@app.get("/", response_class=JSONResponse)
async def root():
    return {
        "code": 0,
        "msg": "æœåŠ¡è¿è¡Œä¸­",
        "docs_url": f"http://{HTTP_HOST}:{HTTP_PORT}/docs",
        "redoc_url": f"http://{HTTP_HOST}:{HTTP_PORT}/redoc"
    }


if __name__ == "__main__":
    logger.info(f"ğŸš€ å¯åŠ¨FastAPIæœåŠ¡ | åœ°å€ï¼šhttp://{HTTP_HOST}:{HTTP_PORT}")
    logger.info(f"ğŸ“š APIæ–‡æ¡£åœ°å€ï¼šhttp://{HTTP_HOST}:{HTTP_PORT}/docs")

    uvicorn.run(
        app=app,
        host=HTTP_HOST,
        port=HTTP_PORT,
        log_level="info",
        workers=1,
        timeout_keep_alive=60
    )
